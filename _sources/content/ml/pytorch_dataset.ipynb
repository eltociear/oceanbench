{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e8f179",
   "metadata": {},
   "source": [
    "# Pytorch Dataset Integration Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import oceanbench._src.datasets.base as xrda\n",
    "import oceanbench._src.geoprocessing.validation as val\n",
    "import oceanbench._src.data as dat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import xarray as xr\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(xrda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83302f",
   "metadata": {},
   "source": [
    "## Torch dataset wrapper of the XRDABatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b775b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class XrTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, batcher: xrda.XRDABatcher, item_postpro=None):\n",
    "        self.batcher = batcher\n",
    "        self.postpro = item_postpro\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.batcher[idx].load().values\n",
    "        if self.postpro:\n",
    "            item = self.postpro(item)\n",
    "        return item\n",
    "    \n",
    "    def reconstruct_from_batches(self, batches, **rec_kws):\n",
    "        return self.batcher.reconstruct([*itertools.chain(*batches)], **rec_kws)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batcher)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ca8c6",
   "metadata": {},
   "source": [
    "## 1D - 1 variable, Patching Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8855d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training data\n",
    "raw_data = xr.tutorial.load_dataset(\"air_temperature\")\n",
    "TrainingItem = collections.namedtuple('TrainingItem', ('air',))\n",
    "data = (\n",
    "    raw_data[[*TrainingItem._fields]].isel(lon=5, lat=5, time=slice(0, 1000))\n",
    "    .sortby('time')\n",
    "    .to_array().transpose('variable', 'time').load()\n",
    ")\n",
    "\n",
    "# Instantiate the patching logic\n",
    "patches = dict(time=200)\n",
    "strides = dict(time=160)\n",
    "batcher = xrda.XRDABatcher(\n",
    "    da=data,\n",
    "    patches=patches,\n",
    "    strides=strides,\n",
    "    check_full_scan=True\n",
    ")\n",
    "\n",
    "\n",
    "# Instantiate the \n",
    "torch_ds = XrTorchDataset(batcher, item_postpro=TrainingItem._make)\n",
    "dataloader = torch.utils.data.DataLoader(torch_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "items = [torch_ds[i] for i in range(len(torch_ds))]\n",
    "ex_item = items[0]\n",
    "batch = next(iter(dataloader))\n",
    "print(f\"Number of items: {len(torch_ds)}\")  \n",
    "print(f\"Item shape: {ex_item.air.shape=}\")\n",
    "print(f\"Batch shape: {batch.air.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e475f767",
   "metadata": {},
   "source": [
    "### Visualizing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(figsize=(10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe3819",
   "metadata": {},
   "source": [
    "### Visualizing the items with the overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 6, figsize=(15, 3))\n",
    "for i, (item, ax) in enumerate(zip(items, axs)):\n",
    "    ax.plot(item.air, 'k',)\n",
    "    l = None\n",
    "    if i > 0:\n",
    "        l, = ax.plot(range(40), item.air[:40], 'b-', label='overlap')\n",
    "        \n",
    "    if i < 5:\n",
    "        l, = ax.plot(range(160, 200), item.air[160:], 'b-', label='overlap')\n",
    "    if i == 0:\n",
    "        ax.legend(handles=[l])\n",
    "    ax.set_title(f'Item {i}')\n",
    "    ax.set_ylim([data.min(), data.max()])\n",
    "    ax.set_xticks([], labels=None)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_yticks([], labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e1a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58449b8e",
   "metadata": {},
   "source": [
    "## 2D Patching Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183305ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training data\n",
    "raw_data = xr.tutorial.load_dataset(\"eraint_uvz\")\n",
    "TrainingItem = collections.namedtuple('TrainingItem', ('u', 'v'))\n",
    "data = (\n",
    "    raw_data[[*TrainingItem._fields]].isel(longitude=slice(None, 400), latitude=slice(None, 200), month=0, level=0)\n",
    "    .sortby('longitude').sortby('latitude')\n",
    "    .to_array().transpose('variable', 'latitude', 'longitude').load()\n",
    ")\n",
    "\n",
    "# Instantiate the patching logic\n",
    "patches = dict(longitude=100, latitude=50)\n",
    "batcher = xrda.XRDABatcher(\n",
    "    da=data,\n",
    "    patches=patches,\n",
    "    strides=patches, # No overlap\n",
    "    check_full_scan=True\n",
    ")\n",
    "\n",
    "\n",
    "# Instantiate the \n",
    "torch_ds = XrTorchDataset(batcher, item_postpro=TrainingItem._make)\n",
    "dataloader = torch.utils.data.DataLoader(torch_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "items = [torch_ds[i] for i in range(len(torch_ds))]\n",
    "ex_item = items[0]\n",
    "batch = next(iter(dataloader))\n",
    "             \n",
    "print(f\"Item shape: {ex_item.u.shape=}, {ex_item.v.shape=}\")\n",
    "print(f\"Batch shape: {batch.u.shape=}, {batch.v.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010af776",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset length is {len(torch_ds)}, \\n Number of patches per dims are {torch_ds.batcher.da_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ac074",
   "metadata": {},
   "source": [
    "### Vizualizing the patch process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45f5f6",
   "metadata": {},
   "source": [
    "#### Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ca92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(row='variable', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c2fca",
   "metadata": {},
   "source": [
    "#### Items drawn from the torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches(items_to_plot, nbaxes=(4, 4)):\n",
    "    fig, axs = plt.subplots(*nbaxes, figsize=(5, 2.5))\n",
    "\n",
    "    for item, ax in zip( items_to_plot, [*itertools.chain(*reversed(axs))]):\n",
    "        ax.imshow(item, cmap='RdBu_r', vmax=70, vmin=-70, origin='lower')\n",
    "        ax.set_xticks([], labels=None)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_yticks([], labels=None)\n",
    "\n",
    "        \n",
    "print(\"Patches of u\")\n",
    "plot_patches([i.u for i in items] )\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nPatches of v\")\n",
    "plot_patches([i.v for i in items])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3910e2",
   "metadata": {},
   "source": [
    "#### Reconstructing the amplitude of the speed from the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ds = torch_ds.reconstruct_from_batches((np.sqrt(batch.u**2 + batch.v**2) for batch in dataloader), dims_labels=['latitude', 'longitude'])\n",
    "rec_ds.plot(figsize=(5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228c0de",
   "metadata": {},
   "source": [
    "#### Reconstructing the laplacian (~ vorticity) from the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13de98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ds = torch_ds.reconstruct_from_batches(((np.diff(batch.u, axis=1, prepend=0) + np.diff(batch.v,axis=2, prepend=0)) for batch in dataloader), dims_labels=['latitude', 'longitude'])\n",
    "rec_ds.plot(figsize=(5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87a6a9",
   "metadata": {},
   "source": [
    "**We see that the border of the patches creates artifact during the derivative: We can fix it by using overlapping patches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2724790",
   "metadata": {},
   "source": [
    "#### Solution with overlapping patches (stride smaller than patch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6923172",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = dict(longitude=100, latitude=50)\n",
    "strides = dict(longitude=60, latitude=30)\n",
    "batcher = xrda.XRDABatcher(\n",
    "    da=data, patches=patches, strides=strides, check_full_scan=True\n",
    ")\n",
    "\n",
    "rec_weight = np.ones((50, 100)) # Weight for each pixel of one patch\n",
    "rec_weight[:10] = 0 # do not use the border pixels during the reconstruction\n",
    "rec_weight[:, :20] = 0\n",
    "rec_weight[-10:] = 0\n",
    "rec_weight[:, -20:] = 0\n",
    "\n",
    "# Instantiate the \n",
    "torch_ds = XrTorchDataset(batcher, item_postpro=TrainingItem._make)\n",
    "dataloader = torch.utils.data.DataLoader(torch_ds, batch_size=4, shuffle=False)\n",
    "rec_ds = torch_ds.reconstruct_from_batches(\n",
    "    ((np.diff(batch.u, axis=1, prepend=0) + np.diff(batch.v,axis=2, prepend=0)) for batch in dataloader),\n",
    "    dims_labels=['latitude', 'longitude'],\n",
    "    weight=rec_weight,\n",
    ")\n",
    "rec_ds.plot(figsize=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patches of u with overlap\")\n",
    "plot_patches([torch_ds[i].u for i in range(len(torch_ds))], (6,6))\n",
    "plt.show()\n",
    "print(\"\\n\\nPatches of u with reconstruction mask\")\n",
    "plot_patches([torch_ds[i].u * rec_weight for i in range(len(torch_ds))], (6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfcd77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": "oceanbench",
   "language": "python",
   "name": "oceanbench"
  },
  "source_map": [
   12,
   16,
   20,
   24,
   37,
   40,
   44,
   64,
   68,
   100,
   104,
   106,
   110,
   129,
   131,
   135,
   168,
   170,
   174,
   178,
   180,
   184,
   201,
   205,
   208,
   212,
   215,
   219,
   223,
   248,
   256
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}